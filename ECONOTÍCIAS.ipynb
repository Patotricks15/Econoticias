{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECONOTÍCIAS",
      "provenance": [],
      "collapsed_sections": [
        "flZTFIjL61od",
        "5CuHfethbdfu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb-rCSAO9wJr"
      },
      "source": [
        "Bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nt7Zr8c3B-o"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "!pip install unidecode -q\n",
        "from unidecode import unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiaW1gguX2Nq"
      },
      "source": [
        "# Notícias mais recentes sobre Economia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_NTuF--moEI"
      },
      "source": [
        "## Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEg3bH2JSdtz"
      },
      "source": [
        "def g1():\n",
        "  url =  'https://g1.globo.com/economia/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "\n",
        "  print(f'                    G1 - ECONOMIA ({url})\\n\\n')\n",
        "  noticia_lista = soup.find_all('a', class_= 'feed-post-link gui-color-primary gui-color-hover', href=True)\n",
        "  horario_lista = soup.find_all('span', class_='feed-post-datetime')\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('>')[1][:-3]\n",
        "    horario = str(horario_lista[i]).split('>')[1][:-6]\n",
        "    link = str(noticia_lista[i]).split('\"')[3]\n",
        "    print(f'\\n\\n{noticia}\\n{horario} ----> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def bbc_br():\n",
        "  url =  'https://www.bbc.com/portuguese/topics/cvjp2jr0k9rt'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    BBC BRASIL - ECONOMIA ({url})\\n\\n')\n",
        "\n",
        "\n",
        "  noticia_lista = soup.find_all('span',  class_=\"lx-stream-post__header-text gs-u-align-middle\")\n",
        "  horario_lista = soup.find_all('span', class_=\"qa-post-auto-meta\")\n",
        "  link_lista = soup.find_all('a',  class_=\"qa-heading-link lx-stream-post__header-link\", href=True)\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('>')[1][:-6]\n",
        "    horario = str(horario_lista[i]).split('>')[1][:-6]\n",
        "    link = 'www.bbc.com' + str(link_lista[i]).split('href=\"')[1].split('\">')[0]\n",
        "    print(f'{noticia}\\n{horario} ---->  {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def nexo():\n",
        "  url =  'https://www.nexojornal.com.br/tema/Economia'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    NEXO JORNAL - ECONOMIA ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('h4',  class_=\"Teaser__title-dark___1HEzZ\")\n",
        "  horario_lista = soup.find_all('span', class_=\"qa-post-auto-meta\")\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('alt=\"')[1].split('\" href=\"')[0]\n",
        "    link =  str(noticia_lista[i]).split('\" href=\"')[1].split('\" title=\"')[0]\n",
        "    link_final = 'www.nexojornal.com.br' + link\n",
        "    print(f'{noticia}\\n{link_final}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def valor():\n",
        "  url =  'https://valor.globo.com/busca/?q=economia&page=1'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    VALOR ECONÔMICO ({url})\\n\\n')\n",
        "\n",
        "\n",
        "  noticia_lista = soup.find_all('div',  class_=\"widget--info__title product-color \")\n",
        "  horario_lista = soup.find_all('div', class_=\"widget--info__meta\")\n",
        "  link_lista = soup.find_all('a')\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('>')[1][:-7].split('\\n')[1]\n",
        "    horario = str(horario_lista[i]).split('>')[1][:-5]\n",
        "    link = str(link_lista[i]).split('<div')[0].split('\"')[1]\n",
        "    print(f'{noticia}\\n          {horario}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def bloomberg_br():\n",
        "  url =  'https://www.bloomberg.com.br/blog/category/noticias-exclusivas/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    BLOOMBERG Brasil - ECONOMIA({url})\\n\\n')\n",
        "\n",
        "\n",
        "  noticia_lista = soup.find_all('h3', class_=\"h3-regular-8\")\n",
        "  horario_lista = soup.find_all('div', class_=\"widget--info__meta\")\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('\">')[2].split('</a>')[0]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\">')[0]\n",
        "    print(f'{noticia}\\n{link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def infomoney():\n",
        "  url =  'https://www.infomoney.com.br/ultimas-noticias/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                   INFOMONEY ({url})\\n\\n')\n",
        "\n",
        "\n",
        "  noticia_lista = soup.find_all('span', class_=\"hl-title hl-title-2\")\n",
        "  horario_lista = soup.find_all('span',  class_=\"posted-diff\")\n",
        "  for i in range(len(noticia_lista[:8])):\n",
        "    noticia = str(noticia_lista[i]).split('title=\"')[1].split('</a>')[0].split('\">')[0]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\" title')[0]\n",
        "    horario = str(horario_lista[i]).split('\">')[1].split('</span>')[0]\n",
        "    print(f'{noticia}\\n{horario} ----> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def valorinveste():\n",
        "  url =  'https://valorinveste.globo.com/ultimas-noticias/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    VALOR INVESTE ({url})\\n\\n')\n",
        "\n",
        "\n",
        "  noticia_lista = soup.find_all('a', class_=\"feed-post-link gui-color-primary gui-color-hover\")\n",
        "  horario_lista = soup.find_all('span',  class_=\"feed-post-datetime\")\n",
        "\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('\">')[1].split('</a>')[0]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\">')[0]\n",
        "    horario = str(horario_lista[i]).split('\">')[1].split('</span>')[0]\n",
        "    print(f'{noticia}\\n{horario} ----> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def braziljournal():\n",
        "  url =  'https://braziljournal.com/categoria/economia'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    BRAZILJOURNAL - ECONOMIA ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('a', class_=\"article-title\")\n",
        "  horario_lista = soup.find_all('div',  class_=\"article-date\")\n",
        "\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('href=\"')[1].split('\">')[1][:-4]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\">')[0]\n",
        "    horario = str(horario_lista[i]).split('\">')[1].split('</div>')[0]\n",
        "    print(f'{noticia}\\n{horario} ----> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def exame():\n",
        "  url =  'https://exame.com/economia/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    EXAME - ECONOMIA ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('span', class_=\"list-item-title\")\n",
        "  horario_lista = soup.find_all('span',  class_=\"list-date-description\")\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('title=\"')[1].split('\">')[0]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\" title=')[0]\n",
        "    horario = str(horario_lista[i]).split('\">')[1].split('</span>')[0]\n",
        "\n",
        "    print(f'{noticia}\\n{horario} ----> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def estadao():\n",
        "  url =  'https://economia.estadao.com.br/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    ESTADÃO - ECONOMIA ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('section', class_=\"col-md-12 col-sm-12 col-xs-12 init item-lista\")\n",
        "  horario_lista = soup.find_all('span',  class_=\"list-date-description\")\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('\" title=')[7].split('> <h3 class=\"third\">')[0][1:][:-1]\n",
        "    link = str(noticia_lista[i]).split('data-href=\"')[1].split('data-title=')[0]\n",
        "    horario = str(noticia_lista[i]).split('class=\"data-posts\">')[1].split('</span>')[0]\n",
        "    print(f'{noticia}\\n{horario} ----> {link}')\n",
        "    \n",
        "#_______________________________________________________________________________________________________________________\n",
        "def ibre():\n",
        "  url =  'https://blogdoibre.fgv.br/'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    BLOG DO IBRE(FGV) ({url})\\n\\n')\n",
        "\n",
        "\n",
        "  noticia_lista = soup.find_all('div', class_=\"views-field views-field-title\", href=False)\n",
        "  horario_lista = soup.find_all('div', class_=\"views-field views-field-nothing-1\")\n",
        "  for i in range(len(noticia_lista[:10])):\n",
        "    noticia = str(noticia_lista[i]).split('\">')[3].split('</a>')[0]\n",
        "    link = 'https://blogdoibre.fgv.br' + str(noticia_lista[i]).split('href=\"')[1].split('</a>')[0].split('\">')[0]\n",
        "    horario = str(horario_lista[i]).split('single\">')[1].split('</span>')[0]\n",
        "    print(f'{noticia}\\n{horario} ---> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def vox():\n",
        "  url =  'https://www.vox.com/search?q=economy'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    VOX - ECONOMY ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('h2', class_=\"c-entry-box--compact__title\")\n",
        "  horario_lista = soup.find_all('time',  class_=\"c-byline__item\")\n",
        "\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('\">')[2][:-(len('</a></h2>'))]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\">')[0]\n",
        "    horario = str(horario_lista[i]).split('\">')[1].split('\\n')[1][len('          '):]\n",
        "    print(f'{noticia}\\n{horario} ---> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def fintimes():\n",
        "  url =  'https://www.ft.com/search?q=economy&sort=date'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    FINANCIAL TIMES - ECONOMY ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('div', class_=\"o-teaser__heading\")\n",
        "  horario_lista = soup.find_all('time',  class_=\"o-teaser__timestamp-date\")\n",
        "\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('\">')[2].split('</a')[0]\n",
        "    link = 'www.ft.com' + str(noticia_lista[i]).split('href=\"')[1].split('\">')[0]\n",
        "    horario = str(horario_lista[i]).split('\">')[1][:-len('</time>')]\n",
        "    print(f'{noticia}\\n{horario} ---> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def nytimes():\n",
        "  url =  'https://www.nytimes.com/search?query=economy'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    THE NEW YORK TIMES - ECONOMY ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('div', class_=\"css-e1lvw9\")\n",
        "  horario_lista = soup.find_all('span', class_=\"css-bc0f0m\")\n",
        "  for i in range(len(noticia_lista[:4])):\n",
        "    link = 'www.nytimes.com' + str(noticia_lista[i]).split('href=\"')[1].split('\"><h4')[0]\n",
        "    noticia = str(noticia_lista[i]).split('4k\">')[1].split('</h')[0]\n",
        "    horario = str(horario_lista[i]).split('</span>')[2].split(', P')[0]\n",
        "    print(f'{noticia}\\n{horario} ---> {link}\\n')\n",
        "\n",
        "#_______________________________________________________________________________________________________________________\n",
        "def bbc():\n",
        "  url =  'https://www.bbc.co.uk/search?q=economy&page=1'\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.content, 'html.parser')\n",
        "  print(f'                    BBC - ECONOMY ({url})\\n\\n')\n",
        "\n",
        "  noticia_lista = soup.find_all('div', class_=\"css-v4rel9-PromoContent e1f5wbog0\")\n",
        "  horario_lista = soup.find_all('div', class_=\"css-3r6h34-PromoContentMetadata e1f5wbog6\")\n",
        "  for i in range(len(noticia_lista)):\n",
        "    noticia = str(noticia_lista[i]).split('\"false\">')[1].split('</span>')[0]\n",
        "    horario = str(horario_lista[i]).split('aria-hidden=\"false\">')[1].split('</span>')[0]\n",
        "    link = str(noticia_lista[i]).split('href=\"')[1].split('\"><span')[0]\n",
        "    print(f'{noticia}\\n{horario} ---> {link}\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flZTFIjL61od"
      },
      "source": [
        "## NACIONAIS\n",
        "*   G1\n",
        "*   BBC Brasil\n",
        "*   Nexo Jornal\n",
        "*   Valor econômico\n",
        "*   Valor Invest\n",
        "*   Brazil Journal\n",
        "*   Infomoney\n",
        "*   Estadão\n",
        "*   Bloomberg Brasil\n",
        "*   Exame\n",
        "*   Blog do IBRE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1ihGQG06gzR"
      },
      "source": [
        "G1 - ECONOMIA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGbSJ5y-6fyb"
      },
      "source": [
        "g1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZynh26h6w8V"
      },
      "source": [
        "BBB Brasil - ECONOMIA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_BypB66-4B"
      },
      "source": [
        "bbc_br()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dihpypIm7BnA"
      },
      "source": [
        "NEXO - ECONOMIA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb4mtdTs7Ie-"
      },
      "source": [
        "nexo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYRlN0Yp7OF0"
      },
      "source": [
        "VALOR ECONÔMICO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA7E6hb37QJg"
      },
      "source": [
        "valor() #Tá sem os links"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV3Ez_tE7Zpf"
      },
      "source": [
        "BLOOMBERG BRASIL - ECONOMIA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIsYf4HI9D0M"
      },
      "source": [
        "bloomberg_br()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDiv7MG99Pp6"
      },
      "source": [
        "INFOMONEY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZexvCwdo9Qyx"
      },
      "source": [
        "infomoney()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZxQWYsp9R96"
      },
      "source": [
        "VALOR INVESTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeZnJzlE9TNe"
      },
      "source": [
        "valorinveste()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfQW0mPk9q6l"
      },
      "source": [
        "BRAZIL JOURNAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pqUYbhv9svT"
      },
      "source": [
        "braziljournal()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gbsymcmaUUk"
      },
      "source": [
        "EXAME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvumLcQCaZSu"
      },
      "source": [
        "exame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8GG7WglaevO"
      },
      "source": [
        "ESTADÃO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It_OhGN1ahDv"
      },
      "source": [
        "estadao()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k2YX14Ga4c6"
      },
      "source": [
        "BLOG DO IBRE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qziK6blbDzb"
      },
      "source": [
        "ibre()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CuHfethbdfu"
      },
      "source": [
        "## INTERNACIONAIS\n",
        "*   Vox\n",
        "*   Financial times\n",
        "*   New york times\n",
        "*   BBC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmvQpYERbfZU"
      },
      "source": [
        "VOX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyHOc7bibiJ8"
      },
      "source": [
        "vox()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rky2CaEpbmx8"
      },
      "source": [
        "FINANCIAL TIMES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOkBc8ulbogX"
      },
      "source": [
        "fintimes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8b-h-EEbtf1"
      },
      "source": [
        "THE NEW YORK TIMES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_zfdTHIbvb9"
      },
      "source": [
        "nytimes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOP5Xe-vcRuw"
      },
      "source": [
        "BBC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50o0r16vcTN-"
      },
      "source": [
        "bbc()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}